## The future is parallel: What's a programmer to do?

I've read [these slides][steele-parallel] by Guy Steele about the differences in linear vs parallel computing and about the old habits that we still have.

Some quotes:

### Motivation

> * Good sequential code minimizes total number of operations.
>   * Clever tricks to reuse previously computed results.
>   * Good parallel code often performs redundant operations to reduce communication.
> * Good sequential algorithms minimize space usage.
>   * Clever tricks to reuse storage.
>   * Good parallel code often requires extra space to permit temporal decoupling.
> * Sequential idioms stress linear problem decomposition.
>   * Process one thing at a time and accumulate results.
>   * Good parallel code usually requires multiway problem decomposition and multiway aggregation of results.

### A New Mindset

> * DO loops are so 1950s! (Literally: Fortran is now 50 years old.)
> * So are linear linked lists! (Literally: Lisp is now 50 years old.)
> * Java-style iterators are so last millennium!
> * Even arrays are suspect!  
> * As soon as you say ``first, SUM = 0`` you are hosed. Accumulators are BAD.
> * If you say, “process subproblems in order,” you lose.
> * The great tricks of the sequential past DON’T WORK.
> * The programming idioms that have become second nature to us as everyday tools DON’T WORK.

### The Parallel Future

> * We need new strategies for problem decomposition.
> * Data structure design/object relationships
> * Algorithmic organization
> * Don’t split a problem into “the first” and “the rest.”
> * Do split a problem into roughly equal pieces. Then figure out how to combine general subsolutions.
> * Often this makes combining the results a bit harder.
> * We need programming languages and runtime implementations that support parallel strategies and hybrid sequential/parallel strategies.
> * We must learn to manage new space-time tradeoffs

### Conclusion

> * A program organized according to linear problem decomposition principles can be really hard to parallelize.
> * A program organized according to parallel problem decomposition principles is easily run either in parallel or sequentially, according to available resources.
> * The new strategy has costs and overheads. They will be reduced over time but will not disappear.
> * In a world of parallel computers of wildly varying sizes, this is our only hope for program portability in the future.
> * Better language design can encourage better parallel programming.

Tags: representation, computation, catamorphism, list, associativity
commutativity, idempotency, abstract-data-type, slide, operator, mapreduce, mindset, comparison, parallel, guy-steele,  linear-computing, parallel-computing

[steele-parallel]: http://groups.csail.mit.edu/mac/users/gjs/6.945/readings/MITApril2009Steele.pdf
